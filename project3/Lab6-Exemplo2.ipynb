{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eeb9441-d2df-4781-8ae5-6b8a566f7504",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "## <font color='blue'>Armazenamento e Gestão de Dados com Data Lake e Data Lakehouse</font>\n",
    "## <font color='blue'>Lab 6</font>\n",
    "### <font color='blue'>Operações CRUD e Time Travel com Delta Lake</font>\n",
    "### <font color='blue'>Exemplo 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c6d00f-b05e-4b9d-a043-b11340c28906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col, to_json, lit, collect_list, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab0fc4d-de5d-4f74-a242-49bb858b5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do Spark com Delta Lake\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Lab6Exemplo2\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", \"5000\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ac0b49-a450-4242-979a-27db959e0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67298cc1-8f96-45fd-b2c4-6e7a2c40b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o nível de log\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6686183e-7a32-44d4-9f34-7a98bbb20069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho da tabela Delta\n",
    "delta_table_path = \"/repositorio/dsa-delta-table-exemplo2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34efcba9-2e79-46fc-9061-f95aee480ccd",
   "metadata": {},
   "source": [
    "## Executando as Operações em Sequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b125324-9767-4ab7-89eb-109b09eeb8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE - Cria o dataframe com os dados iniciais\n",
    "dsa_dados = spark.createDataFrame([\n",
    "    (1, \"Ana\", 30, \"Cientista de Dados\"),\n",
    "    (2, \"Bob\", 18, \"Analista de Dados\"),\n",
    "    (3, \"Charlie\", 35, \"Arquiteto de Dados\"),\n",
    "    (4, \"Mark\", 40, \"Engenheiro de Dados\"),\n",
    "    (5, \"Eve\", 28, \"Engenheiro de IA\"),\n",
    "    (6, \"Frank\", 50, \"Engenheiro de ML\"),\n",
    "    (7, \"Grace\", 29, \"Engenheiro DataOps\"),\n",
    "    (8, \"Hank\", 33, \"Engenheiro de Dados\")\n",
    "], [\"id\", \"nome\", \"idade\", \"funcao\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f07c9dd-13b6-46c6-8485-cb47fa8ebe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Gravar dados na tabela Delta\n",
    "dsa_dados.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262328bd-34c2-4e3d-87ae-160a9d72d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados iniciais:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------------------+\n",
      "| id|   nome|idade|             funcao|\n",
      "+---+-------+-----+-------------------+\n",
      "|  3|Charlie|   35| Arquiteto de Dados|\n",
      "|  7|  Grace|   29| Engenheiro DataOps|\n",
      "|  8|   Hank|   33|Engenheiro de Dados|\n",
      "|  4|   Mark|   40|Engenheiro de Dados|\n",
      "|  6|  Frank|   50|   Engenheiro de ML|\n",
      "|  1|    Ana|   30| Cientista de Dados|\n",
      "|  2|    Bob|   18|  Analista de Dados|\n",
      "|  5|    Eve|   28|   Engenheiro de IA|\n",
      "+---+-------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# READ - Ler os dados\n",
    "print(\"Dados iniciais:\")\n",
    "spark.read.format(\"delta\").load(delta_table_path).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28b44f6-ee7d-4422-baf3-932f4f71ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após atualização de Ana:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:======================================================> (49 + 1) / 50]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-----------------------+\n",
      "|id |nome   |idade|funcao                 |\n",
      "+---+-------+-----+-----------------------+\n",
      "|1  |Ana    |32   |Gerente de Data Science|\n",
      "|3  |Charlie|35   |Arquiteto de Dados     |\n",
      "|7  |Grace  |29   |Engenheiro DataOps     |\n",
      "|8  |Hank   |33   |Engenheiro de Dados    |\n",
      "|4  |Mark   |40   |Engenheiro de Dados    |\n",
      "|6  |Frank  |50   |Engenheiro de ML       |\n",
      "|2  |Bob    |18   |Analista de Dados      |\n",
      "|5  |Eve    |28   |Engenheiro de IA       |\n",
      "+---+-------+-----+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# UPDATE - Atualizar idade e função de um funcionário\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "delta_table.update(\n",
    "    condition = \"nome = 'Ana'\",\n",
    "    set = {\"idade\": \"32\", \"funcao\": \"'Gerente de Data Science'\"}\n",
    ")\n",
    "print(\"Após atualização de Ana:\")\n",
    "delta_table.toDF().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e84bfd-3050-465c-bd3b-2263407764ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após remoção de funcionários com idade <= 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-----------------------+\n",
      "|id |nome   |idade|funcao                 |\n",
      "+---+-------+-----+-----------------------+\n",
      "|1  |Ana    |32   |Gerente de Data Science|\n",
      "|3  |Charlie|35   |Arquiteto de Dados     |\n",
      "|7  |Grace  |29   |Engenheiro DataOps     |\n",
      "|8  |Hank   |33   |Engenheiro de Dados    |\n",
      "|4  |Mark   |40   |Engenheiro de Dados    |\n",
      "|6  |Frank  |50   |Engenheiro de ML       |\n",
      "|5  |Eve    |28   |Engenheiro de IA       |\n",
      "+---+-------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DELETE - Remover registros com idade menor ou igual a 18\n",
    "delta_table.delete(condition = \"idade <= 18\")\n",
    "print(\"Após remoção de funcionários com idade <= 18:\")\n",
    "delta_table.toDF().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e66065-b789-4bc1-a684-db04a3c3e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após inserção de novos registros:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-----------------------+\n",
      "|id |nome   |idade|funcao                 |\n",
      "+---+-------+-----+-----------------------+\n",
      "|1  |Ana    |32   |Gerente de Data Science|\n",
      "|3  |Charlie|35   |Arquiteto de Dados     |\n",
      "|11 |Liam   |26   |Engenheiro de Dados    |\n",
      "|7  |Grace  |29   |Engenheiro DataOps     |\n",
      "|8  |Hank   |33   |Engenheiro de Dados    |\n",
      "|4  |Mark   |40   |Engenheiro de Dados    |\n",
      "|10 |Jake   |31   |Analytics Engineer     |\n",
      "|9  |Ivy    |27   |Analytics Engineer     |\n",
      "|6  |Frank  |50   |Engenheiro de ML       |\n",
      "|5  |Eve    |28   |Engenheiro de IA       |\n",
      "+---+-------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INSERT - Inserir múltiplos novos registros\n",
    "new_employees = spark.createDataFrame([\n",
    "    (9, \"Ivy\", 27, \"Analytics Engineer\"),\n",
    "    (10, \"Jake\", 31, \"Analytics Engineer\"),\n",
    "    (11, \"Liam\", 26, \"Engenheiro de Dados\")\n",
    "], [\"id\", \"nome\", \"idade\", \"funcao\"])\n",
    "\n",
    "delta_table.alias(\"existingData\").merge(\n",
    "    new_employees.alias(\"newData\"),\n",
    "    \"existingData.id = newData.id\"\n",
    ").whenNotMatchedInsertAll().execute()\n",
    "\n",
    "print(\"Após inserção de novos registros:\")\n",
    "delta_table.toDF().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2776c2c-524c-41f3-820b-e906cea60750",
   "metadata": {},
   "source": [
    "## UPSERT - Inserir ou Atualizar (Merge) Dados Existentes e Novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "463f7e5a-6626-4b86-a6c4-56dbac77670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após upsert (atualização/inserção):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-----------------------+\n",
      "|id |nome   |idade|funcao                 |\n",
      "+---+-------+-----+-----------------------+\n",
      "|1  |Ana    |32   |Gerente de Data Science|\n",
      "|11 |Liam   |26   |Engenheiro de Dados    |\n",
      "|7  |Grace  |29   |Engenheiro DataOps     |\n",
      "|8  |Hank   |33   |Engenheiro de Dados    |\n",
      "|4  |Mark   |40   |Engenheiro de Dados    |\n",
      "|10 |Jake   |31   |Analytics Engineer     |\n",
      "|9  |Ivy    |27   |Analytics Engineer     |\n",
      "|6  |Frank  |50   |Engenheiro de ML       |\n",
      "|3  |Charlie|36   |Arquiteto de Dados     |\n",
      "|12 |Maria  |24   |Arquiteto RPA          |\n",
      "|5  |Eve    |28   |Engenheiro de IA       |\n",
      "+---+-------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UPSERT - Inserir ou Atualizar (Merge) dados existentes e novos\n",
    "upsert_data = spark.createDataFrame([\n",
    "    (3, \"Charlie\", 36, \"Arquiteto de Dados\"),  # Atualizar idade de Charlie\n",
    "    (12, \"Maria\", 24, \"Arquiteto RPA\")  # Novo registro\n",
    "], [\"id\", \"nome\", \"idade\", \"funcao\"])\n",
    "\n",
    "delta_table.alias(\"oldData\").merge(\n",
    "    upsert_data.alias(\"upsertData\"),\n",
    "    \"oldData.id = upsertData.id\"\n",
    ").whenMatchedUpdate(set={\n",
    "    \"idade\": \"upsertData.idade\",\n",
    "    \"funcao\": \"upsertData.funcao\"\n",
    "}).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "print(\"Após upsert (atualização/inserção):\")\n",
    "delta_table.toDF().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96373163-d5fa-4f2e-b6d5-a531fbaf8201",
   "metadata": {},
   "source": [
    "## Filtros e Análises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88639fe9-e9be-40b7-9866-f376923ee95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcionários que são Engenheiros de Dados:\n",
      "+---+----+-----+-------------------+\n",
      "|id |nome|idade|funcao             |\n",
      "+---+----+-----+-------------------+\n",
      "|11 |Liam|26   |Engenheiro de Dados|\n",
      "|8  |Hank|33   |Engenheiro de Dados|\n",
      "|4  |Mark|40   |Engenheiro de Dados|\n",
      "+---+----+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrar funcionários com uma determinada função\n",
    "print(\"Funcionários que são Engenheiros de Dados:\")\n",
    "delta_table.toDF().filter(\"funcao = 'Engenheiro de Dados'\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86a3f9ab-231a-45cb-b72c-a81b7a6fd01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de idade por função:\n",
      "+-----------------------+----------+\n",
      "|funcao                 |avg(idade)|\n",
      "+-----------------------+----------+\n",
      "|Gerente de Data Science|32.0      |\n",
      "|Engenheiro de Dados    |33.0      |\n",
      "|Engenheiro DataOps     |29.0      |\n",
      "|Analytics Engineer     |29.0      |\n",
      "|Engenheiro de ML       |50.0      |\n",
      "|Engenheiro de IA       |28.0      |\n",
      "|Arquiteto de Dados     |36.0      |\n",
      "|Arquiteto RPA          |24.0      |\n",
      "+-----------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por função e calcular média de idade\n",
    "print(\"Média de idade por função:\")\n",
    "delta_table.toDF().groupBy(\"funcao\").avg(\"idade\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a861678-c7f8-4823-b4b4-ec49486cba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funções com média de idade maior que 30:\n",
      "+-----------------------+----------+\n",
      "|funcao                 |avg(idade)|\n",
      "+-----------------------+----------+\n",
      "|Gerente de Data Science|32.0      |\n",
      "|Engenheiro de Dados    |33.0      |\n",
      "|Engenheiro de ML       |50.0      |\n",
      "|Arquiteto de Dados     |36.0      |\n",
      "+-----------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por função, calcular a média de idade e filtrar por média > 30\n",
    "print(\"Funções com média de idade maior que 30:\")\n",
    "delta_table.toDF() \\\n",
    "    .groupBy(\"funcao\") \\\n",
    "    .avg(\"idade\") \\\n",
    "    .filter(col(\"avg(idade)\") > 30) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af4833-7a1a-49a3-88ee-03389abdfd72",
   "metadata": {},
   "source": [
    "## Histórico de Alterações (Time Travel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28332cb0-b6d4-4c62-83d0-77a63f4a4e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tabela tem 5 versões.\n"
     ]
    }
   ],
   "source": [
    "# Caminho para a tabela Delta\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Obter o histórico completo\n",
    "history_df = delta_table.history()\n",
    "\n",
    "# Contar o número de versões\n",
    "num_versions = history_df.count()\n",
    "print(f\"A tabela tem {num_versions} versões.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b81ba7-ff44-4604-8460-06f777184595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão inicial da tabela:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------------------+\n",
      "|id |nome   |idade|funcao             |\n",
      "+---+-------+-----+-------------------+\n",
      "|3  |Charlie|35   |Arquiteto de Dados |\n",
      "|7  |Grace  |29   |Engenheiro DataOps |\n",
      "|8  |Hank   |33   |Engenheiro de Dados|\n",
      "|4  |Mark   |40   |Engenheiro de Dados|\n",
      "|6  |Frank  |50   |Engenheiro de ML   |\n",
      "|1  |Ana    |30   |Cientista de Dados |\n",
      "|2  |Bob    |18   |Analista de Dados  |\n",
      "|5  |Eve    |28   |Engenheiro de IA   |\n",
      "+---+-------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Acessar a versão mais antiga da tabela (versão 0)\n",
    "print(\"Versão inicial da tabela:\")\n",
    "old_version = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
    "old_version.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fc4baac-e1fa-4c5c-ad35-f7e342dcf569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão 0 da tabela:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------------------+\n",
      "|id |nome   |idade|funcao             |\n",
      "+---+-------+-----+-------------------+\n",
      "|3  |Charlie|35   |Arquiteto de Dados |\n",
      "|7  |Grace  |29   |Engenheiro DataOps |\n",
      "|8  |Hank   |33   |Engenheiro de Dados|\n",
      "|4  |Mark   |40   |Engenheiro de Dados|\n",
      "|6  |Frank  |50   |Engenheiro de ML   |\n",
      "|1  |Ana    |30   |Cientista de Dados |\n",
      "|2  |Bob    |18   |Analista de Dados  |\n",
      "|5  |Eve    |28   |Engenheiro de IA   |\n",
      "+---+-------+-----+-------------------+\n",
      "\n",
      "Versão 1 da tabela:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-----------------------+\n",
      "|id |nome   |idade|funcao                 |\n",
      "+---+-------+-----+-----------------------+\n",
      "|1  |Ana    |32   |Gerente de Data Science|\n",
      "|3  |Charlie|35   |Arquiteto de Dados     |\n",
      "|7  |Grace  |29   |Engenheiro DataOps     |\n",
      "|8  |Hank   |33   |Engenheiro de Dados    |\n",
      "|4  |Mark   |40   |Engenheiro de Dados    |\n",
      "|6  |Frank  |50   |Engenheiro de ML       |\n",
      "|2  |Bob    |18   |Analista de Dados      |\n",
      "|5  |Eve    |28   |Engenheiro de IA       |\n",
      "+---+-------+-----+-----------------------+\n",
      "\n",
      "Versão 4 da tabela:\n",
      "+---+-------+-----+-----------------------+\n",
      "|id |nome   |idade|funcao                 |\n",
      "+---+-------+-----+-----------------------+\n",
      "|1  |Ana    |32   |Gerente de Data Science|\n",
      "|11 |Liam   |26   |Engenheiro de Dados    |\n",
      "|7  |Grace  |29   |Engenheiro DataOps     |\n",
      "|8  |Hank   |33   |Engenheiro de Dados    |\n",
      "|4  |Mark   |40   |Engenheiro de Dados    |\n",
      "|10 |Jake   |31   |Analytics Engineer     |\n",
      "|9  |Ivy    |27   |Analytics Engineer     |\n",
      "|6  |Frank  |50   |Engenheiro de ML       |\n",
      "|3  |Charlie|36   |Arquiteto de Dados     |\n",
      "|12 |Maria  |24   |Arquiteto RPA          |\n",
      "|5  |Eve    |28   |Engenheiro de IA       |\n",
      "+---+-------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Versão 0 da tabela:\")\n",
    "version_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
    "version_0.show(truncate=False)\n",
    "\n",
    "print(\"Versão 1 da tabela:\")\n",
    "version_1 = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(delta_table_path)\n",
    "version_1.show(truncate=False)\n",
    "\n",
    "print(\"Versão 4 da tabela:\")\n",
    "version_4 = spark.read.format(\"delta\").option(\"versionAsOf\", 4).load(delta_table_path)\n",
    "version_4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38b001a2-9ff0-4240-b036-a9716b3d230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar uma coluna que identifica a versão\n",
    "version_0 = version_0.withColumn(\"versao\", lit(0))\n",
    "version_4 = version_4.withColumn(\"versao\", lit(4))\n",
    "\n",
    "# Unir as duas versões\n",
    "changes = version_0.union(version_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3b6d58a-8fda-47e7-974f-4044f7e27173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alterações entre versões:\n",
      "+---+-----+-------+\n",
      "|id |nome |versoes|\n",
      "+---+-----+-------+\n",
      "|2  |Bob  |[0]    |\n",
      "|11 |Liam |[4]    |\n",
      "|10 |Jake |[4]    |\n",
      "|9  |Ivy  |[4]    |\n",
      "|12 |Maria|[4]    |\n",
      "+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar as diferenças em relação ao nome\n",
    "print(\"Alterações entre versões:\")\n",
    "changes.groupBy(\"id\", \"nome\") \\\n",
    "       .agg(collect_list(\"versao\").alias(\"versoes\")) \\\n",
    "       .filter(size(\"versoes\") == 1) \\\n",
    "       .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a4787fe-0ee4-4f61-93e0-3ae178ac8a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alterações entre versões:\n",
      "+---+-----+-------+\n",
      "|id |idade|versoes|\n",
      "+---+-----+-------+\n",
      "|3  |35   |[0]    |\n",
      "|1  |30   |[0]    |\n",
      "|2  |18   |[0]    |\n",
      "|1  |32   |[4]    |\n",
      "|11 |26   |[4]    |\n",
      "|10 |31   |[4]    |\n",
      "|9  |27   |[4]    |\n",
      "|3  |36   |[4]    |\n",
      "|12 |24   |[4]    |\n",
      "+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar as diferenças em relação a idade\n",
    "print(\"Alterações entre versões:\")\n",
    "changes.groupBy(\"id\", \"idade\") \\\n",
    "       .agg(collect_list(\"versao\").alias(\"versoes\")) \\\n",
    "       .filter(size(\"versoes\") == 1) \\\n",
    "       .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f8543f7-4579-465c-91b2-cf1c7a9f7bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histórico de alterações da tabela Delta (formatado):\n",
      "+------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|Versão|Operação|Métricas                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |Metadados do Usuário|\n",
      "+------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|4     |MERGE   |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1284, numTargetBytesRemoved -> 1322, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 1, executionTimeMs -> 2503, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 1457, numTargetRowsUpdated -> 1, numOutputRows -> 2, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 2, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 723}|NULL                |\n",
      "|3     |MERGE   |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 3, numTargetBytesAdded -> 3902, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 0, executionTimeMs -> 1858, numTargetRowsInserted -> 3, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 0, numTargetRowsUpdated -> 0, numOutputRows -> 3, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 3, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 1846}     |NULL                |\n",
      "|2     |DELETE  |{numRemovedFiles -> 1, numRemovedBytes -> 1287, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1334, numDeletionVectorsUpdated -> 0, numDeletedRows -> 1, scanTimeMs -> 995, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 338}                                                                                                                                                                                                                                                                                                                             |NULL                |\n",
      "|1     |UPDATE  |{numRemovedFiles -> 1, numRemovedBytes -> 1293, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 2213, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1738, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1329, rewriteTimeMs -> 472}                                                                                                                                                                                                                                                                                                                         |NULL                |\n",
      "|0     |WRITE   |{numFiles -> 8, numOutputRows -> 8, numOutputBytes -> 10400}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL                |\n",
      "+------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carrega a tabela delta\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Carregar o histórico de alterações da tabela Delta\n",
    "history = delta_table.history()\n",
    "\n",
    "# Selecionar apenas as colunas relevantes\n",
    "formatted_history = history.select(\n",
    "    col(\"version\").alias(\"Versão\"),\n",
    "    col(\"operation\").alias(\"Operação\"),\n",
    "    col(\"operationMetrics\").alias(\"Métricas\"),\n",
    "    col(\"userMetadata\").alias(\"Metadados do Usuário\")\n",
    ")\n",
    "\n",
    "# Mostrar as alterações \n",
    "print(\"Histórico de alterações da tabela Delta (formatado):\")\n",
    "formatted_history.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9f2ac6c-884f-4e84-ac21-daac0571fe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|Versão|Operação|Métricas                                                                                                                                                                                                                                                                                                                      |Metadados do Usuário|\n",
      "+------+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|1     |UPDATE  |{numRemovedFiles -> 1, numRemovedBytes -> 1293, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 2213, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1738, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1329, rewriteTimeMs -> 472}|NULL                |\n",
      "+------+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se você quiser exibir apenas operações específicas (por exemplo, UPDATE), pode usar .filter():\n",
    "filtered_history = formatted_history.filter(col(\"Operação\") == \"UPDATE\")\n",
    "filtered_history.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64e8a148-0c1f-489a-9a46-60757e6b7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histórico salvo em: output\n"
     ]
    }
   ],
   "source": [
    "# Carregar o histórico de alterações da tabela Delta\n",
    "history = delta_table.history()\n",
    "\n",
    "# Selecionar e formatar as colunas\n",
    "formatted_history = history.select(\n",
    "    col(\"version\").alias(\"Versão\"),\n",
    "    col(\"operation\").alias(\"Operação\"),\n",
    "    to_json(col(\"operationMetrics\")).alias(\"Métricas\"),  # Converter MAP para JSON, para conseguir salvar em CSV\n",
    "    col(\"userMetadata\").alias(\"Metadados do Usuário\")\n",
    ")\n",
    "\n",
    "# Salvar o histórico formatado em CSV\n",
    "output_path = \"output\"\n",
    "formatted_history.write.format(\"csv\").option(\"header\", \"true\").save(output_path)\n",
    "\n",
    "print(f\"Histórico salvo em: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cabbc2-9079-4dcc-af2a-1967de7dee21",
   "metadata": {},
   "source": [
    "Embora não haja um comando direto de rollback no Delta Lake, você pode sobrescrever uma nova versão com os dados de uma versão anterior sem perder todo o histórico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ef8d77f-074d-4652-9a6c-39c4c9b72b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-----------------------+\n",
      "|id |nome   |idade|funcao                 |\n",
      "+---+-------+-----+-----------------------+\n",
      "|1  |Ana    |32   |Gerente de Data Science|\n",
      "|3  |Charlie|35   |Arquiteto de Dados     |\n",
      "|7  |Grace  |29   |Engenheiro DataOps     |\n",
      "|8  |Hank   |33   |Engenheiro de Dados    |\n",
      "|4  |Mark   |40   |Engenheiro de Dados    |\n",
      "|6  |Frank  |50   |Engenheiro de ML       |\n",
      "|5  |Eve    |28   |Engenheiro de IA       |\n",
      "+---+-------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consultar uma versão antiga (versão 2)\n",
    "spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(delta_table_path).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2adfe83d-b445-4265-b6a6-7c0f3fe3f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a versão 2\n",
    "old_version = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52a9b773-de7e-49a3-b8dd-9a945d487445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Sobrescrever a tabela principal com a versão 2\n",
    "# Isso vai gerar uma cópia da versão 2 que será agora a versão principal. \n",
    "old_version.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ffb26bf-ee6d-4e89-bfec-e8047cee4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-----------------------+\n",
      "|id |nome   |idade|funcao                 |\n",
      "+---+-------+-----+-----------------------+\n",
      "|1  |Ana    |32   |Gerente de Data Science|\n",
      "|3  |Charlie|35   |Arquiteto de Dados     |\n",
      "|4  |Mark   |40   |Engenheiro de Dados    |\n",
      "|8  |Hank   |33   |Engenheiro de Dados    |\n",
      "|7  |Grace  |29   |Engenheiro DataOps     |\n",
      "|6  |Frank  |50   |Engenheiro de ML       |\n",
      "|5  |Eve    |28   |Engenheiro de IA       |\n",
      "+---+-------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar os dados sobrescritos\n",
    "spark.read.format(\"delta\").load(delta_table_path).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d72eca9a-eb03-4d03-ab1e-16feb8893a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tabela tem 6 versões.\n"
     ]
    }
   ],
   "source": [
    "# Caminho para a tabela Delta\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Obter o histórico completo\n",
    "history_df = delta_table.history()\n",
    "\n",
    "# Contar o número de versões\n",
    "num_versions = history_df.count()\n",
    "print(f\"A tabela tem {num_versions} versões.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c630fa-769a-4848-bb1f-ba74f9b23bc3",
   "metadata": {},
   "source": [
    "Considerações:\n",
    "\n",
    "- A operação de sobrescrita cria uma nova versão na tabela Delta. Dados atuais ainda estarão no histórico, mas os dados sobrescritos substituem a visão principal da tabela.\n",
    "\n",
    "- Certifique-se de que o esquema da versão antiga é compatível com o esquema atual. Caso contrário, pode ser necessário habilitar a opção overwriteSchema.\n",
    "\n",
    "- Em ambientes críticos, prefira corrigir os dados com operações como MERGE ou UPDATE em vez de sobrescrever diretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83dc7b4-990a-40ad-9967-b9a33be04409",
   "metadata": {},
   "source": [
    "## VACUUM Com Valor Seguro Para Retenção\n",
    "\n",
    "Por padrão, o Delta Lake impõe uma retenção mínima de 7 dias para garantir que operações como time travel ainda sejam possíveis e para evitar exclusão acidental de dados necessários para transações. Se você quiser reduzir esse período, será necessário modificar a configuração de retenção mínima.\n",
    "\n",
    "Você não poderá acessar versões anteriores além do período de retenção configurado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa4a2707-aa84-4bd2-bf6c-4671241e070b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Desativar temporariamente a proteção para retenção mínima\n",
    "spark.sql(\"SET spark.databricks.delta.retentionDurationCheck.enabled = false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaabe9c2-cb20-4d01-b348-8998b8e3e507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando vacuum com retenção de 1 dia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 files and directories in a total of 1 directories.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executar VACUUM com retenção de 1 dia\n",
    "print(\"Executando vacuum com retenção de 1 dia...\")\n",
    "delta_table.vacuum(retentionHours=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2a33278-067e-48c6-a1c0-12398acb1e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reativar a proteção para retenção mínima\n",
    "spark.sql(\"SET spark.databricks.delta.retentionDurationCheck.enabled = true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71728fff-cf08-475d-8324-c0dca783c0e8",
   "metadata": {},
   "source": [
    "Se o VACUUM foi executado com um período curto de retenção, versões mais antigas podem ter sido excluídas e não estarão disponíveis no histórico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c717b208-85de-4a15-b297-ae607f5f11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finaliza a sessão Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892408a-a8a2-4197-83d5-e8bccb618f33",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
